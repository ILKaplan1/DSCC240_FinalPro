{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69d9781",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3291ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_by_review = pd.read_csv(\"reviewparagraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fe49446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping of pos_tags to wordnet lemmatizer via \n",
    "#https://stackoverflow.com/questions/61982023/using-wordnetlemmatizer-lemmatize-with-pos-tags-throws-keyerror\n",
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8a9345cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0%\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 70%\n",
      "Progress: 80%\n",
      "Progress: 90%\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "list = movie_by_review['text']\n",
    "\n",
    "count = 0\n",
    "text_clean = []\n",
    "\n",
    "#for each tuple in df\n",
    "for i in list:\n",
    "    if(count % math.floor(len(list)/10) == 0):\n",
    "        print('Progress: '+str(math.ceil(count*100/len(list)))+\"%\")\n",
    "    count += 1\n",
    "    \n",
    "    #tokenizing\n",
    "    tokens = nltk.word_tokenize(str(i))\n",
    "    \n",
    "    #pos-tagging\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    lemmatized = []\n",
    "    \n",
    "    #lemmatizing with corresponding pos_tags\n",
    "    for word, tag in tagged:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag is None:\n",
    "            lemmatized.append(word)\n",
    "        else:\n",
    "            lemmatized.append(lemmatizer.lemmatize(word, wn_tag))\n",
    "       \n",
    "    #removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for w in lemmatized:\n",
    "        if w in stop_words:\n",
    "            lemmatized.remove(w)\n",
    "            \n",
    "    #remove less than 3 letters\n",
    "    final_word_list = lemmatized.copy()\n",
    "    #for word in final_word_list:\n",
    "     #   if (len(word)<3):\n",
    "     #       final_word_list.remove(word)\n",
    "    \n",
    "    #remove any remaining numbers/characters\n",
    "    text_clean.append(' '.join([i for i in final_word_list if i.isalpha()]))  \n",
    "    \n",
    "\n",
    "#add column on data frame\n",
    "movie_by_review['cleaned_text'] = text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9073a5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "      <td>film adapt comic book plenty success whether s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>cv001</td>\n",
       "      <td>18431</td>\n",
       "      <td>0</td>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>every movie come along suspect studio every in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>cv002</td>\n",
       "      <td>15918</td>\n",
       "      <td>0</td>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "      <td>pos</td>\n",
       "      <td>get mail work alot good deserve order make fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>cv003</td>\n",
       "      <td>11664</td>\n",
       "      <td>0</td>\n",
       "      <td>\" jaws \" is a rare film that grabs your attent...</td>\n",
       "      <td>pos</td>\n",
       "      <td>jaw rare film grab attention show single image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>cv004</td>\n",
       "      <td>11636</td>\n",
       "      <td>0</td>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>pos</td>\n",
       "      <td>moviemaking lot like general manager nfl team ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fold_id cv_tag  html_id  sent_id  \\\n",
       "0           0        0  cv000    29590        0   \n",
       "1          25        0  cv001    18431        0   \n",
       "2          64        0  cv002    15918        0   \n",
       "3          83        0  cv003    11664        0   \n",
       "4         125        0  cv004    11636        0   \n",
       "\n",
       "                                                text  tag  \\\n",
       "0  films adapted from comic books have had plenty...  pos   \n",
       "1  every now and then a movie comes along from a ...  pos   \n",
       "2  you've got mail works alot better than it dese...  pos   \n",
       "3  \" jaws \" is a rare film that grabs your attent...  pos   \n",
       "4  moviemaking is a lot like being the general ma...  pos   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  film adapt comic book plenty success whether s...  \n",
       "1  every movie come along suspect studio every in...  \n",
       "2  get mail work alot good deserve order make fil...  \n",
       "3  jaw rare film grab attention show single image...  \n",
       "4  moviemaking lot like general manager nfl team ...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_by_review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split             \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer                    \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentences = movie_by_review['cleaned_text'].values\n",
    "y = np.where(movie_by_review['tag'] == \"pos\", '1','0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '0', '0', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
    "                                                sentences, y,  \n",
    "                                                test_size=0.20,  \n",
    "                                                random_state=265)\n",
    "\n",
    "y_train = [str(x) for x in y_train]\n",
    "y_test = [str(x) for x in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=31347)\n",
    "tokenizer.fit_on_texts(sentences_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding 1 because of  reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1                          \n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='pre', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='pre', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = create_embedding_matrix('data/glove_word_embeddings/glove.6B.50d.txt',tokenizer.word_index,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [int(x) for x in y_train]\n",
    "y_test = [int(x) for x in y_test]\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 6s 164ms/step - loss: 0.6922 - accuracy: 0.5225 - val_loss: 0.6871 - val_accuracy: 0.5425\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.6358 - accuracy: 0.9287 - val_loss: 0.6776 - val_accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 0.5325 - accuracy: 0.9975 - val_loss: 0.6446 - val_accuracy: 0.6925\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.3387 - accuracy: 0.9975 - val_loss: 0.5846 - val_accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.7650\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.7725\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.7725\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.7700\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 5s 167ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.7750\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d7a9306864d1722659d2dfd77d3184129925096cfb3edbe67bf0f058d880a9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
