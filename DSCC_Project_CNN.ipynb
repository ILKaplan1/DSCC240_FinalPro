{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69d9781",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a162bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31d6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31146888",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"../cleaned_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ae1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(1000):\n",
    "    score.append(1)\n",
    "for i in range(1000):\n",
    "    score.append(0)\n",
    "reviews['Score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1d08ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>film adapt comic book plenty success whether s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>every movie come along suspect studio every in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>get mail work alot good deserve order make fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jaw rare film grab attention show single image...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>moviemaking lot like general manager nfl team ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>anything stigmata take warning release film re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>john boorman zardoz goofy cinematic debacle fu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>kid hall acquired taste take least season watc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>time john carpenter great horror director cour...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>two party guy bob head haddaway dance hit love...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                       cleaned_text  Score\n",
       "0              0  film adapt comic book plenty success whether s...      1\n",
       "1              1  every movie come along suspect studio every in...      1\n",
       "2              2  get mail work alot good deserve order make fil...      1\n",
       "3              3  jaw rare film grab attention show single image...      1\n",
       "4              4  moviemaking lot like general manager nfl team ...      1\n",
       "...          ...                                                ...    ...\n",
       "1995        1995  anything stigmata take warning release film re...      0\n",
       "1996        1996  john boorman zardoz goofy cinematic debacle fu...      0\n",
       "1997        1997  kid hall acquired taste take least season watc...      0\n",
       "1998        1998  time john carpenter great horror director cour...      0\n",
       "1999        1999  two party guy bob head haddaway dance hit love...      0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f76ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['film',\n",
       " 'adapt',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'plenty',\n",
       " 'success',\n",
       " 'whether',\n",
       " 'superheroes',\n",
       " 'batman',\n",
       " 'superman',\n",
       " 'spawn',\n",
       " 'gear',\n",
       " 'toward',\n",
       " 'kid',\n",
       " 'casper',\n",
       " 'arthouse',\n",
       " 'crowd',\n",
       " 'ghost',\n",
       " 'world',\n",
       " 'there',\n",
       " 'never',\n",
       " 'really',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'like',\n",
       " 'hell',\n",
       " 'starter',\n",
       " 'create',\n",
       " 'alan',\n",
       " 'moore',\n",
       " 'eddie',\n",
       " 'campbell',\n",
       " 'bring',\n",
       " 'medium',\n",
       " 'whole',\n",
       " 'new',\n",
       " 'level',\n",
       " 'mid',\n",
       " 'series',\n",
       " 'call',\n",
       " 'watchman',\n",
       " 'say',\n",
       " 'moore',\n",
       " 'campbell',\n",
       " 'thoroughly',\n",
       " 'research',\n",
       " 'subject',\n",
       " 'jack',\n",
       " 'ripper',\n",
       " 'would',\n",
       " 'like',\n",
       " 'say',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'start',\n",
       " 'look',\n",
       " 'little',\n",
       " 'odd',\n",
       " 'book',\n",
       " 'graphic',\n",
       " 'novel',\n",
       " 'over',\n",
       " 'page',\n",
       " 'long',\n",
       " 'include',\n",
       " 'nearly',\n",
       " 'consist',\n",
       " 'nothing',\n",
       " 'footnote',\n",
       " 'word',\n",
       " 'dismiss',\n",
       " 'film',\n",
       " 'source',\n",
       " 'can',\n",
       " 'get',\n",
       " 'past',\n",
       " 'whole',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'thing',\n",
       " 'you',\n",
       " 'might',\n",
       " 'find',\n",
       " 'another',\n",
       " 'stumble',\n",
       " 'block',\n",
       " 'hell',\n",
       " 'director',\n",
       " 'albert',\n",
       " 'allen',\n",
       " 'hughes',\n",
       " 'hughes',\n",
       " 'brother',\n",
       " 'direct',\n",
       " 'seem',\n",
       " 'almost',\n",
       " 'ludicrous',\n",
       " 'cast',\n",
       " 'carrot',\n",
       " 'top',\n",
       " 'well',\n",
       " 'anything',\n",
       " 'riddle',\n",
       " 'this',\n",
       " 'better',\n",
       " 'direct',\n",
       " 'film',\n",
       " 'set',\n",
       " 'ghetto',\n",
       " 'feature',\n",
       " 'really',\n",
       " 'violent',\n",
       " 'street',\n",
       " 'crime',\n",
       " 'mad',\n",
       " 'geniuses',\n",
       " 'behind',\n",
       " 'menace',\n",
       " 'ii',\n",
       " 'society',\n",
       " 'ghetto',\n",
       " 'question',\n",
       " 'course',\n",
       " 'whitechapel',\n",
       " 'london',\n",
       " 'east',\n",
       " 'end',\n",
       " 'filthy',\n",
       " 'sooty',\n",
       " 'place',\n",
       " 'whore',\n",
       " 'call',\n",
       " 'unfortunates',\n",
       " 'start',\n",
       " 'get',\n",
       " 'little',\n",
       " 'nervous',\n",
       " 'this',\n",
       " 'mysterious',\n",
       " 'psychopath',\n",
       " 'carve',\n",
       " 'their',\n",
       " 'profession',\n",
       " 'surgical',\n",
       " 'precision',\n",
       " 'first',\n",
       " 'stiff',\n",
       " 'turn',\n",
       " 'copper',\n",
       " 'peter',\n",
       " 'godley',\n",
       " 'robbie',\n",
       " 'coltrane',\n",
       " 'world',\n",
       " 'not',\n",
       " 'enough',\n",
       " 'call',\n",
       " 'inspector',\n",
       " 'frederick',\n",
       " 'abberline',\n",
       " 'johnny',\n",
       " 'depp',\n",
       " 'blow',\n",
       " 'crack',\n",
       " 'case',\n",
       " 'widower',\n",
       " 'prophetic',\n",
       " 'dream',\n",
       " 'unsuccessfully',\n",
       " 'try',\n",
       " 'quell',\n",
       " 'copious',\n",
       " 'amount',\n",
       " 'absinthe',\n",
       " 'opium',\n",
       " 'arrive',\n",
       " 'whitechapel',\n",
       " 'befriend',\n",
       " 'unfortunate',\n",
       " 'name',\n",
       " 'mary',\n",
       " 'kelly',\n",
       " 'heather',\n",
       " 'graham',\n",
       " 'say',\n",
       " 'proceeds',\n",
       " 'investigate',\n",
       " 'horribly',\n",
       " 'gruesome',\n",
       " 'crime',\n",
       " 'that',\n",
       " 'even',\n",
       " 'police',\n",
       " 'surgeon',\n",
       " 'ca',\n",
       " 'stomach',\n",
       " 'think',\n",
       " 'anyone',\n",
       " 'need',\n",
       " 'brief',\n",
       " 'jack',\n",
       " 'ripper',\n",
       " 'wo',\n",
       " 'go',\n",
       " 'particular',\n",
       " 'say',\n",
       " 'moore',\n",
       " 'campbell',\n",
       " 'unique',\n",
       " 'interesting',\n",
       " 'theory',\n",
       " 'identity',\n",
       " 'killer',\n",
       " 'reason',\n",
       " 'choose',\n",
       " 'slay',\n",
       " 'comic',\n",
       " 'bother',\n",
       " 'cloak',\n",
       " 'identity',\n",
       " 'ripper',\n",
       " 'screenwriter',\n",
       " 'terry',\n",
       " 'hayes',\n",
       " 'vertical',\n",
       " 'limit',\n",
       " 'rafael',\n",
       " 'yglesias',\n",
       " 'les',\n",
       " 'mis',\n",
       " 'rables',\n",
       " 'a',\n",
       " 'good',\n",
       " 'job',\n",
       " 'keep',\n",
       " 'hide',\n",
       " 'viewer',\n",
       " 'end',\n",
       " 'funny',\n",
       " 'watch',\n",
       " 'local',\n",
       " 'blindly',\n",
       " 'point',\n",
       " 'the',\n",
       " 'finger',\n",
       " 'blame',\n",
       " 'jew',\n",
       " 'indian',\n",
       " 'englishman',\n",
       " 'could',\n",
       " 'never',\n",
       " 'capable',\n",
       " 'commit',\n",
       " 'ghastly',\n",
       " 'act',\n",
       " 'hell',\n",
       " 'end',\n",
       " 'have',\n",
       " 'whistle',\n",
       " 'the',\n",
       " 'stonecutter',\n",
       " 'song',\n",
       " 'the',\n",
       " 'simpson',\n",
       " 'day',\n",
       " 'hold',\n",
       " 'back',\n",
       " 'the',\n",
       " 'electric',\n",
       " 'make',\n",
       " 'steve',\n",
       " 'guttenberg',\n",
       " 'a',\n",
       " 'star',\n",
       " 'worry',\n",
       " 'all',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'you',\n",
       " 'see',\n",
       " 'onto',\n",
       " 'from',\n",
       " 'hell',\n",
       " 'appearance',\n",
       " 'certainly',\n",
       " 'dark',\n",
       " 'bleak',\n",
       " 'enough',\n",
       " 'surprising',\n",
       " 'see',\n",
       " 'much',\n",
       " 'it',\n",
       " 'look',\n",
       " 'like',\n",
       " 'a',\n",
       " 'tim',\n",
       " 'burton',\n",
       " 'film',\n",
       " 'than',\n",
       " 'planet',\n",
       " 'the',\n",
       " 'ape',\n",
       " 'time',\n",
       " 'it',\n",
       " 'seem',\n",
       " 'like',\n",
       " 'sleepy',\n",
       " 'hollow',\n",
       " 'print',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'completely',\n",
       " 'finish',\n",
       " 'both',\n",
       " 'color',\n",
       " 'music',\n",
       " 'have',\n",
       " 'not',\n",
       " 'finalize',\n",
       " 'no',\n",
       " 'comment',\n",
       " 'marilyn',\n",
       " 'manson',\n",
       " 'cinematographer',\n",
       " 'peter',\n",
       " 'deming',\n",
       " 'do',\n",
       " 'say',\n",
       " 'a',\n",
       " 'word',\n",
       " 'ably',\n",
       " 'capture',\n",
       " 'the',\n",
       " 'dreariness',\n",
       " 'of',\n",
       " 'london',\n",
       " 'help',\n",
       " 'make',\n",
       " 'the',\n",
       " 'flashy',\n",
       " 'killing',\n",
       " 'scene',\n",
       " 'remind',\n",
       " 'me',\n",
       " 'of',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'flashback',\n",
       " 'twin',\n",
       " 'peak',\n",
       " 'even',\n",
       " 'though',\n",
       " 'the',\n",
       " 'violence',\n",
       " 'the',\n",
       " 'film',\n",
       " 'pale',\n",
       " 'comparison',\n",
       " 'that',\n",
       " 'the',\n",
       " 'comic',\n",
       " 'winner',\n",
       " 'martin',\n",
       " 'child',\n",
       " 'shakespeare',\n",
       " 'love',\n",
       " 'production',\n",
       " 'design',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'original',\n",
       " 'prague',\n",
       " 'surroundings',\n",
       " 'one',\n",
       " 'creepy',\n",
       " 'place',\n",
       " 'the',\n",
       " 'act',\n",
       " 'from',\n",
       " 'hell',\n",
       " 'be',\n",
       " 'solid',\n",
       " 'the',\n",
       " 'dreamy',\n",
       " 'depp',\n",
       " 'turn',\n",
       " 'a',\n",
       " 'typically',\n",
       " 'strong',\n",
       " 'performance',\n",
       " 'deftly',\n",
       " 'handle',\n",
       " 'a',\n",
       " 'british',\n",
       " 'accent',\n",
       " 'holm',\n",
       " 'joe',\n",
       " 'gould',\n",
       " 'secret',\n",
       " 'richardson',\n",
       " 'dalmatian',\n",
       " 'log',\n",
       " 'great',\n",
       " 'support',\n",
       " 'role',\n",
       " 'the',\n",
       " 'big',\n",
       " 'surprise',\n",
       " 'be',\n",
       " 'graham',\n",
       " 'cringe',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'open',\n",
       " 'mouth',\n",
       " 'imagine',\n",
       " 'attempt',\n",
       " 'an',\n",
       " 'irish',\n",
       " 'accent',\n",
       " 'it',\n",
       " 'actually',\n",
       " 'be',\n",
       " 'half',\n",
       " 'bad',\n",
       " 'film',\n",
       " 'however',\n",
       " 'be',\n",
       " 'all',\n",
       " 'good',\n",
       " 'r',\n",
       " 'strong',\n",
       " 'sexuality',\n",
       " 'language',\n",
       " 'drug',\n",
       " 'content',\n",
       " 'every',\n",
       " 'movie',\n",
       " 'come',\n",
       " 'along',\n",
       " 'suspect',\n",
       " 'studio',\n",
       " 'every',\n",
       " 'indication',\n",
       " 'stinker',\n",
       " 'everybody',\n",
       " 'surprise',\n",
       " 'perhaps',\n",
       " 'even',\n",
       " 'studio',\n",
       " 'film',\n",
       " 'become',\n",
       " 'critical',\n",
       " 'darling',\n",
       " 'film',\n",
       " 'high',\n",
       " 'school',\n",
       " 'comedy',\n",
       " 'star',\n",
       " 'matthew',\n",
       " 'broderick',\n",
       " 'reese',\n",
       " 'witherspoon',\n",
       " 'current',\n",
       " 'example',\n",
       " 'anybody',\n",
       " 'know',\n",
       " 'film',\n",
       " 'exist',\n",
       " 'week',\n",
       " 'open',\n",
       " 'plot',\n",
       " 'deceptively',\n",
       " 'simple',\n",
       " 'washington',\n",
       " 'carver',\n",
       " 'high',\n",
       " 'school',\n",
       " 'student',\n",
       " 'election',\n",
       " 'flick',\n",
       " 'reese',\n",
       " 'witherspoon',\n",
       " 'her',\n",
       " 'hand',\n",
       " 'raise',\n",
       " 'nearly',\n",
       " 'every',\n",
       " 'question',\n",
       " 'way',\n",
       " 'way',\n",
       " 'high',\n",
       " 'matthew',\n",
       " 'broderick',\n",
       " 'sick',\n",
       " 'megalomaniac',\n",
       " 'student',\n",
       " 'encourage',\n",
       " 'paul',\n",
       " 'jock',\n",
       " 'run',\n",
       " 'paul',\n",
       " 'nihilistic',\n",
       " 'sister',\n",
       " 'jump',\n",
       " 'race',\n",
       " 'well',\n",
       " 'personal',\n",
       " 'reason',\n",
       " 'dark',\n",
       " 'side',\n",
       " 'such',\n",
       " 'sleeper',\n",
       " 'success',\n",
       " 'expectation',\n",
       " 'low',\n",
       " 'go',\n",
       " 'fact',\n",
       " 'quality',\n",
       " 'stuff',\n",
       " 'make',\n",
       " 'review',\n",
       " 'even',\n",
       " 'enthusiastic',\n",
       " 'any',\n",
       " 'right',\n",
       " 'ca',\n",
       " 'help',\n",
       " 'go',\n",
       " 'baggage',\n",
       " 'glow',\n",
       " 'review',\n",
       " 'contrast',\n",
       " 'negative',\n",
       " 'baggage',\n",
       " 'reviewer',\n",
       " 'likely',\n",
       " 'good',\n",
       " 'film',\n",
       " 'live',\n",
       " 'hype',\n",
       " 'make',\n",
       " 'disappointing',\n",
       " 'contain',\n",
       " 'significant',\n",
       " 'plot',\n",
       " 'detail',\n",
       " 'lift',\n",
       " 'directly',\n",
       " 'release',\n",
       " 'few',\n",
       " 'month',\n",
       " 'earlier',\n",
       " 'similarity',\n",
       " 'staggering',\n",
       " 'tracy',\n",
       " 'flick',\n",
       " 'president',\n",
       " 'extraordinary',\n",
       " 'number',\n",
       " 'club',\n",
       " 'involve',\n",
       " 'the',\n",
       " 'school',\n",
       " 'play',\n",
       " 'fischer',\n",
       " 'the',\n",
       " 'president',\n",
       " 'extraordinary',\n",
       " 'number',\n",
       " 'club',\n",
       " 'involve',\n",
       " 'with',\n",
       " 'the',\n",
       " 'school',\n",
       " 'play',\n",
       " 'significant',\n",
       " 'tension',\n",
       " 'the',\n",
       " 'potential',\n",
       " 'relationship',\n",
       " 'teacher',\n",
       " 'his',\n",
       " 'student',\n",
       " 'significant',\n",
       " 'tension',\n",
       " 'the',\n",
       " 'potential',\n",
       " 'relationship',\n",
       " 'teacher',\n",
       " 'his',\n",
       " 'student',\n",
       " 'flick',\n",
       " 'single',\n",
       " 'parent',\n",
       " 'home',\n",
       " 'contribute',\n",
       " 'her',\n",
       " 'drive',\n",
       " 'fischer',\n",
       " 'single',\n",
       " 'parent',\n",
       " 'home',\n",
       " 'have',\n",
       " 'contribute',\n",
       " 'his',\n",
       " 'drive',\n",
       " 'male',\n",
       " 'bumble',\n",
       " 'adult',\n",
       " 'matthew',\n",
       " 'broderick',\n",
       " 'pursue',\n",
       " 'extramarital',\n",
       " 'affair',\n",
       " 'get',\n",
       " 'catch',\n",
       " 'his',\n",
       " 'whole',\n",
       " 'life',\n",
       " 'ruin',\n",
       " 'even',\n",
       " 'get',\n",
       " 'a',\n",
       " 'bee',\n",
       " 'sting',\n",
       " 'male',\n",
       " 'bumble',\n",
       " 'adult',\n",
       " 'bill',\n",
       " 'murray',\n",
       " 'pursue',\n",
       " 'extramarital',\n",
       " 'affair',\n",
       " 'get',\n",
       " 'catch',\n",
       " 'his',\n",
       " 'whole',\n",
       " 'life',\n",
       " 'ruin',\n",
       " 'get',\n",
       " 'several',\n",
       " 'bee',\n",
       " 'sting',\n",
       " 'on',\n",
       " 'happen',\n",
       " 'an',\n",
       " 'individual',\n",
       " 'screenplay',\n",
       " 'a',\n",
       " 'novel',\n",
       " 'contain',\n",
       " 'many',\n",
       " 'significant',\n",
       " 'plot',\n",
       " 'point',\n",
       " 'yet',\n",
       " 'film',\n",
       " 'be',\n",
       " 'probably',\n",
       " 'not',\n",
       " 'even',\n",
       " 'aware',\n",
       " 'each',\n",
       " 'make',\n",
       " 'two',\n",
       " 'different',\n",
       " 'studio',\n",
       " 'a',\n",
       " 'genre',\n",
       " 'the',\n",
       " 'high',\n",
       " 'school',\n",
       " 'geek',\n",
       " 'revenge',\n",
       " 'movie',\n",
       " 'have',\n",
       " 'be',\n",
       " 'fully',\n",
       " 'form',\n",
       " 'yet',\n",
       " 'even',\n",
       " 'the',\n",
       " 'strength',\n",
       " 'rely',\n",
       " 'upon',\n",
       " 'fantastic',\n",
       " 'performance',\n",
       " 'broderick',\n",
       " 'witherspoon',\n",
       " 'newcomer',\n",
       " 'jessica',\n",
       " 'campbell',\n",
       " 'paul',\n",
       " 'sister',\n",
       " 'tammy',\n",
       " 'be',\n",
       " 'play',\n",
       " 'the',\n",
       " 'mr',\n",
       " 'rooney',\n",
       " 'role',\n",
       " 'seem',\n",
       " 'be',\n",
       " 'have',\n",
       " 'the',\n",
       " 'fun',\n",
       " 'he',\n",
       " 'have',\n",
       " 'since',\n",
       " 'be',\n",
       " 'a',\n",
       " 'revelation',\n",
       " 'early',\n",
       " 'the',\n",
       " 'year',\n",
       " 'a',\n",
       " 'comedy',\n",
       " 'teenager',\n",
       " 'have',\n",
       " 'little',\n",
       " 'clout',\n",
       " 'for',\n",
       " 'money',\n",
       " 'witherspoon',\n",
       " 'deserves',\n",
       " 'an',\n",
       " 'oscar',\n",
       " 'nomination',\n",
       " 'campbell',\n",
       " 'character',\n",
       " 'get',\n",
       " 'go',\n",
       " 'like',\n",
       " 'her',\n",
       " 'fantastic',\n",
       " 'speech',\n",
       " 'the',\n",
       " 'gymnasium',\n",
       " 'you',\n",
       " 'win',\n",
       " 'thing',\n",
       " 'be',\n",
       " 'bother',\n",
       " 'since',\n",
       " 'see',\n",
       " 'it',\n",
       " 'be',\n",
       " 'an',\n",
       " 'extraordinary',\n",
       " 'amount',\n",
       " 'sexuality',\n",
       " 'this',\n",
       " 'film',\n",
       " 'suppose',\n",
       " 'that',\n",
       " 'come',\n",
       " 'from',\n",
       " 'mtv',\n",
       " 'film',\n",
       " 'should',\n",
       " 'expect',\n",
       " 'less',\n",
       " 'the',\n",
       " 'film',\n",
       " 'start',\n",
       " 'light',\n",
       " 'airy',\n",
       " 'like',\n",
       " 'a',\n",
       " 'sitcom',\n",
       " 'the',\n",
       " 'screw',\n",
       " 'tighten',\n",
       " 'the',\n",
       " 'tension',\n",
       " 'mount',\n",
       " 'alexander',\n",
       " 'payne',\n",
       " 'decides',\n",
       " 'add',\n",
       " 'element',\n",
       " 'that',\n",
       " 'frankly',\n",
       " 'distract',\n",
       " 'from',\n",
       " 'the',\n",
       " 'story',\n",
       " 'be',\n",
       " 'bad',\n",
       " 'enough',\n",
       " 'that',\n",
       " 'mr',\n",
       " 'like',\n",
       " 'tracy',\n",
       " 'determination',\n",
       " 'win',\n",
       " 'all',\n",
       " 'cost',\n",
       " 'do',\n",
       " 'they',\n",
       " 'have',\n",
       " 'throw',\n",
       " 'the',\n",
       " 'relationship',\n",
       " 'even',\n",
       " 'so',\n",
       " 'logical',\n",
       " 'reason',\n",
       " 'mr',\n",
       " 'have',\n",
       " 'an',\n",
       " 'affair',\n",
       " 'he',\n",
       " 'do',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'like',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'similarity',\n",
       " 'to',\n",
       " 'and',\n",
       " 'the',\n",
       " 'tonal',\n",
       " 'nosedive',\n",
       " 'it',\n",
       " 'take',\n",
       " 'it',\n",
       " 'get',\n",
       " 'explicitly',\n",
       " 'mark',\n",
       " 'this',\n",
       " 'as',\n",
       " 'a',\n",
       " 'disappointment',\n",
       " 'get',\n",
       " 'mail',\n",
       " 'work',\n",
       " 'alot',\n",
       " 'good',\n",
       " 'deserve',\n",
       " 'order',\n",
       " 'make',\n",
       " 'film',\n",
       " 'success',\n",
       " 'cast',\n",
       " 'two',\n",
       " 'extremely',\n",
       " 'popular',\n",
       " 'attractive',\n",
       " 'star',\n",
       " 'them',\n",
       " 'share',\n",
       " 'screen',\n",
       " 'two',\n",
       " 'hour',\n",
       " 'then',\n",
       " 'collect',\n",
       " 'profit',\n",
       " 'real',\n",
       " 'acting',\n",
       " 'involve',\n",
       " 'original',\n",
       " 'inventive',\n",
       " 'bone',\n",
       " 'body',\n",
       " 'basically',\n",
       " 'complete',\n",
       " 'shop',\n",
       " 'around',\n",
       " 'corner',\n",
       " 'add',\n",
       " 'few',\n",
       " 'modern',\n",
       " 'twist',\n",
       " 'go',\n",
       " 'defies',\n",
       " 'concept',\n",
       " 'good',\n",
       " 'contemporary',\n",
       " 'filmmaking',\n",
       " 'overly',\n",
       " 'sentimental',\n",
       " 'at',\n",
       " 'time',\n",
       " 'terribly',\n",
       " 'mushy',\n",
       " 'not',\n",
       " 'mention',\n",
       " 'manipulative',\n",
       " 'oh',\n",
       " 'enjoyable',\n",
       " 'manipulation',\n",
       " 'must',\n",
       " 'something',\n",
       " 'than',\n",
       " 'casting',\n",
       " 'manipulation',\n",
       " 'make',\n",
       " 'movie',\n",
       " 'work',\n",
       " 'well',\n",
       " 'absolutely',\n",
       " 'hat',\n",
       " 'previous',\n",
       " 'team',\n",
       " 'sleepless',\n",
       " 'seattle',\n",
       " 'could',\n",
       " 'directing',\n",
       " 'both',\n",
       " 'film',\n",
       " 'helm',\n",
       " 'woman',\n",
       " 'quite',\n",
       " 'yet',\n",
       " 'figure',\n",
       " 'what',\n",
       " 'like',\n",
       " 'much',\n",
       " 'about',\n",
       " 'you',\n",
       " 'get',\n",
       " 'mail',\n",
       " 'then',\n",
       " 'really',\n",
       " 'important',\n",
       " 'you',\n",
       " 'like',\n",
       " 'something',\n",
       " 'much',\n",
       " 'even',\n",
       " 'question',\n",
       " 'it',\n",
       " 'storyline',\n",
       " 'cliched',\n",
       " 'they',\n",
       " 'come',\n",
       " 'hank',\n",
       " 'play',\n",
       " 'joe',\n",
       " 'fox',\n",
       " 'insanely',\n",
       " 'likeable',\n",
       " 'owner',\n",
       " 'discount',\n",
       " 'book',\n",
       " 'chain',\n",
       " 'meg',\n",
       " 'ryan',\n",
       " 'play',\n",
       " 'kathleen',\n",
       " 'kelley',\n",
       " 'even',\n",
       " 'insanely',\n",
       " 'likeable',\n",
       " 'proprietor',\n",
       " 'a',\n",
       " 'child',\n",
       " 'book',\n",
       " 'shop',\n",
       " 'call',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'homage',\n",
       " 'shop',\n",
       " 'around',\n",
       " 'corner',\n",
       " 'kelley',\n",
       " 'soon',\n",
       " 'become',\n",
       " 'bitter',\n",
       " 'rival',\n",
       " 'new',\n",
       " 'fox',\n",
       " 'book',\n",
       " 'store',\n",
       " 'open',\n",
       " 'right',\n",
       " 'across',\n",
       " 'block',\n",
       " 'small',\n",
       " 'business',\n",
       " 'they',\n",
       " 'know',\n",
       " 'they',\n",
       " 'already',\n",
       " 'love',\n",
       " 'each',\n",
       " 'over',\n",
       " 'internet',\n",
       " 'neither',\n",
       " 'party',\n",
       " 'know',\n",
       " 'other',\n",
       " 'person',\n",
       " 'true',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "for i in reviews.iloc[:,1]:\n",
    "    vocab += i.split(' ')\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a2c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array(vocab)\n",
    "vocab = np.unique(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3977017e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', ..., 'zwick', 'zwigoff', 'zycie'], dtype='<U25')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d760dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "dic = {}\n",
    "for i in vocab:\n",
    "    dic.update({i:num})\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1052489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'aa': 2,\n",
       " 'aaa': 3,\n",
       " 'aaaaaah': 4,\n",
       " 'aaaahhhs': 5,\n",
       " 'aahs': 6,\n",
       " 'aaliyah': 7,\n",
       " 'aalyah': 8,\n",
       " 'aamir': 9,\n",
       " 'aardman': 10,\n",
       " 'aaron': 11,\n",
       " 'aatish': 12,\n",
       " 'ab': 13,\n",
       " 'aback': 14,\n",
       " 'abandon': 15,\n",
       " 'abandoned': 16,\n",
       " 'abandonment': 17,\n",
       " 'abate': 18,\n",
       " 'abba': 19,\n",
       " 'abbe': 20,\n",
       " 'abberation': 21,\n",
       " 'abberline': 22,\n",
       " 'abbot': 23,\n",
       " 'abbott': 24,\n",
       " 'abbotts': 25,\n",
       " 'abbreviated': 26,\n",
       " 'abby': 27,\n",
       " 'abc': 28,\n",
       " 'abdomen': 29,\n",
       " 'abduct': 30,\n",
       " 'abducted': 31,\n",
       " 'abductees': 32,\n",
       " 'abduction': 33,\n",
       " 'abe': 34,\n",
       " 'abel': 35,\n",
       " 'aberdeen': 36,\n",
       " 'aberration': 37,\n",
       " 'abet': 38,\n",
       " 'abeyance': 39,\n",
       " 'abhorrence': 40,\n",
       " 'abhorrent': 41,\n",
       " 'abider': 42,\n",
       " 'abides': 43,\n",
       " 'abigail': 44,\n",
       " 'abiility': 45,\n",
       " 'ability': 46,\n",
       " 'abit': 47,\n",
       " 'abject': 48,\n",
       " 'ablaze': 49,\n",
       " 'able': 50,\n",
       " 'ably': 51,\n",
       " 'abnormal': 52,\n",
       " 'abnormally': 53,\n",
       " 'aboard': 54,\n",
       " 'abode': 55,\n",
       " 'abolish': 56,\n",
       " 'abolitionist': 57,\n",
       " 'abominable': 58,\n",
       " 'abomination': 59,\n",
       " 'aborbed': 60,\n",
       " 'aborginal': 61,\n",
       " 'aboriginal': 62,\n",
       " 'aborigine': 63,\n",
       " 'abort': 64,\n",
       " 'aborted': 65,\n",
       " 'abortion': 66,\n",
       " 'abortionist': 67,\n",
       " 'abortive': 68,\n",
       " 'aboslutely': 69,\n",
       " 'abound': 70,\n",
       " 'abounds': 71,\n",
       " 'about': 72,\n",
       " 'abouts': 73,\n",
       " 'above': 74,\n",
       " 'abraded': 75,\n",
       " 'abraham': 76,\n",
       " 'abrams': 77,\n",
       " 'abrasive': 78,\n",
       " 'abreast': 79,\n",
       " 'abril': 80,\n",
       " 'abroad': 81,\n",
       " 'abrupt': 82,\n",
       " 'abruptly': 83,\n",
       " 'abscond': 84,\n",
       " 'absence': 85,\n",
       " 'absense': 86,\n",
       " 'absent': 87,\n",
       " 'absentee': 88,\n",
       " 'absinthe': 89,\n",
       " 'absoloute': 90,\n",
       " 'absoltuely': 91,\n",
       " 'absolut': 92,\n",
       " 'absolute': 93,\n",
       " 'absolutely': 94,\n",
       " 'absolution': 95,\n",
       " 'absolutist': 96,\n",
       " 'absolve': 97,\n",
       " 'absorb': 98,\n",
       " 'absorbant': 99,\n",
       " 'absorbed': 100,\n",
       " 'absorbing': 101,\n",
       " 'absorbs': 102,\n",
       " 'absorption': 103,\n",
       " 'abstinence': 104,\n",
       " 'abstract': 105,\n",
       " 'abstraction': 106,\n",
       " 'absurd': 107,\n",
       " 'absurdism': 108,\n",
       " 'absurdist': 109,\n",
       " 'absurdity': 110,\n",
       " 'absurdly': 111,\n",
       " 'abu': 112,\n",
       " 'abundance': 113,\n",
       " 'abundant': 114,\n",
       " 'abundantly': 115,\n",
       " 'abundence': 116,\n",
       " 'abuse': 117,\n",
       " 'abused': 118,\n",
       " 'abuser': 119,\n",
       " 'abusive': 120,\n",
       " 'abuzz': 121,\n",
       " 'abysmal': 122,\n",
       " 'abysmally': 123,\n",
       " 'abyss': 124,\n",
       " 'abyssinian': 125,\n",
       " 'academe': 126,\n",
       " 'academia': 127,\n",
       " 'academic': 128,\n",
       " 'academy': 129,\n",
       " 'acast': 130,\n",
       " 'accelerate': 131,\n",
       " 'acceleration': 132,\n",
       " 'accelerator': 133,\n",
       " 'accent': 134,\n",
       " 'accentuate': 135,\n",
       " 'accept': 136,\n",
       " 'acceptable': 137,\n",
       " 'acceptance': 138,\n",
       " 'accepted': 139,\n",
       " 'accepting': 140,\n",
       " 'acception': 141,\n",
       " 'accepts': 142,\n",
       " 'access': 143,\n",
       " 'accessibility': 144,\n",
       " 'accessible': 145,\n",
       " 'accessorize': 146,\n",
       " 'accessory': 147,\n",
       " 'accident': 148,\n",
       " 'accidental': 149,\n",
       " 'accidentally': 150,\n",
       " 'accidentlly': 151,\n",
       " 'accidently': 152,\n",
       " 'acclaim': 153,\n",
       " 'acclaimed': 154,\n",
       " 'acclimatize': 155,\n",
       " 'accolade': 156,\n",
       " 'accommodate': 157,\n",
       " 'accommodating': 158,\n",
       " 'accommodation': 159,\n",
       " 'accomodates': 160,\n",
       " 'accompanies': 161,\n",
       " 'accompaniment': 162,\n",
       " 'accompany': 163,\n",
       " 'accompanying': 164,\n",
       " 'accomplice': 165,\n",
       " 'accomplish': 166,\n",
       " 'accomplished': 167,\n",
       " 'accomplishes': 168,\n",
       " 'accomplishment': 169,\n",
       " 'accord': 170,\n",
       " 'accordance': 171,\n",
       " 'accordingly': 172,\n",
       " 'accordion': 173,\n",
       " 'accost': 174,\n",
       " 'account': 175,\n",
       " 'accountability': 176,\n",
       " 'accountable': 177,\n",
       " 'accountant': 178,\n",
       " 'accumulate': 179,\n",
       " 'accumulation': 180,\n",
       " 'accuracy': 181,\n",
       " 'accurate': 182,\n",
       " 'accurately': 183,\n",
       " 'accursed': 184,\n",
       " 'accusation': 185,\n",
       " 'accuse': 186,\n",
       " 'accused': 187,\n",
       " 'accuser': 188,\n",
       " 'accustom': 189,\n",
       " 'accustomed': 190,\n",
       " 'ace': 191,\n",
       " 'acerbic': 192,\n",
       " 'acerbity': 193,\n",
       " 'ache': 194,\n",
       " 'acheivement': 195,\n",
       " 'acheives': 196,\n",
       " 'achievable': 197,\n",
       " 'achieve': 198,\n",
       " 'achievement': 199,\n",
       " 'achilles': 200,\n",
       " 'achin': 201,\n",
       " 'achingly': 202,\n",
       " 'achoo': 203,\n",
       " 'acid': 204,\n",
       " 'acidic': 205,\n",
       " 'aciton': 206,\n",
       " 'ack': 207,\n",
       " 'ackland': 208,\n",
       " 'acknowledge': 209,\n",
       " 'acknowledgeable': 210,\n",
       " 'acknowledgement': 211,\n",
       " 'acknowledges': 212,\n",
       " 'acknowledgment': 213,\n",
       " 'acme': 214,\n",
       " 'acne': 215,\n",
       " 'acore': 216,\n",
       " 'acouple': 217,\n",
       " 'acquaint': 218,\n",
       " 'acquaintance': 219,\n",
       " 'acquaints': 220,\n",
       " 'acquiescence': 221,\n",
       " 'acquire': 222,\n",
       " 'acquired': 223,\n",
       " 'acquisition': 224,\n",
       " 'acquit': 225,\n",
       " 'acquits': 226,\n",
       " 'acquittal': 227,\n",
       " 'acre': 228,\n",
       " 'acrimonious': 229,\n",
       " 'acrimony': 230,\n",
       " 'acrobat': 231,\n",
       " 'acrobatic': 232,\n",
       " 'acrobatics': 233,\n",
       " 'acronym': 234,\n",
       " 'across': 235,\n",
       " 'acrylic': 236,\n",
       " 'act': 237,\n",
       " 'acted': 238,\n",
       " 'acting': 239,\n",
       " 'action': 240,\n",
       " 'actioner': 241,\n",
       " 'actioners': 242,\n",
       " 'actionfest': 243,\n",
       " 'actionless': 244,\n",
       " 'activate': 245,\n",
       " 'active': 246,\n",
       " 'actively': 247,\n",
       " 'activist': 248,\n",
       " 'activites': 249,\n",
       " 'activity': 250,\n",
       " 'actor': 251,\n",
       " 'actosta': 252,\n",
       " 'actress': 253,\n",
       " 'actresses': 254,\n",
       " 'actual': 255,\n",
       " 'actualisation': 256,\n",
       " 'actuality': 257,\n",
       " 'actualization': 258,\n",
       " 'actualize': 259,\n",
       " 'actually': 260,\n",
       " 'actualy': 261,\n",
       " 'acuity': 262,\n",
       " 'acumen': 263,\n",
       " 'acupuncture': 264,\n",
       " 'acute': 265,\n",
       " 'acutely': 266,\n",
       " 'ad': 267,\n",
       " 'adafarasin': 268,\n",
       " 'adage': 269,\n",
       " 'adagio': 270,\n",
       " 'adair': 271,\n",
       " 'adam': 272,\n",
       " 'adamantly': 273,\n",
       " 'adams': 274,\n",
       " 'adamson': 275,\n",
       " 'adandon': 276,\n",
       " 'adapt': 277,\n",
       " 'adaptable': 278,\n",
       " 'adaptation': 279,\n",
       " 'adapter': 280,\n",
       " 'adaption': 281,\n",
       " 'aday': 282,\n",
       " 'add': 283,\n",
       " 'addam': 284,\n",
       " 'addams': 285,\n",
       " 'added': 286,\n",
       " 'addendum': 287,\n",
       " 'addict': 288,\n",
       " 'addiction': 289,\n",
       " 'addictive': 290,\n",
       " 'addictively': 291,\n",
       " 'addition': 292,\n",
       " 'additional': 293,\n",
       " 'additionally': 294,\n",
       " 'additive': 295,\n",
       " 'addle': 296,\n",
       " 'addled': 297,\n",
       " 'address': 298,\n",
       " 'addy': 299,\n",
       " 'ade': 300,\n",
       " 'adefarasin': 301,\n",
       " 'adelaide': 302,\n",
       " 'adele': 303,\n",
       " 'adept': 304,\n",
       " 'adeptly': 305,\n",
       " 'adeptness': 306,\n",
       " 'adequate': 307,\n",
       " 'adequately': 308,\n",
       " 'adhere': 309,\n",
       " 'adherence': 310,\n",
       " 'adherent': 311,\n",
       " 'adhesive': 312,\n",
       " 'adian': 313,\n",
       " 'adjacent': 314,\n",
       " 'adjani': 315,\n",
       " 'adjective': 316,\n",
       " 'adjectives': 317,\n",
       " 'adjoin': 318,\n",
       " 'adjust': 319,\n",
       " 'adjuster': 320,\n",
       " 'adjustment': 321,\n",
       " 'adlai': 322,\n",
       " 'adlib': 323,\n",
       " 'administer': 324,\n",
       " 'administration': 325,\n",
       " 'administrative': 326,\n",
       " 'administrator': 327,\n",
       " 'admirable': 328,\n",
       " 'admirably': 329,\n",
       " 'admiral': 330,\n",
       " 'admiration': 331,\n",
       " 'admire': 332,\n",
       " 'admired': 333,\n",
       " 'admirer': 334,\n",
       " 'admission': 335,\n",
       " 'admit': 336,\n",
       " 'admits': 337,\n",
       " 'admittance': 338,\n",
       " 'admittedly': 339,\n",
       " 'admitting': 340,\n",
       " 'admittingly': 341,\n",
       " 'admonition': 342,\n",
       " 'ado': 343,\n",
       " 'adolescence': 344,\n",
       " 'adolescent': 345,\n",
       " 'adolf': 346,\n",
       " 'adolph': 347,\n",
       " 'adopt': 348,\n",
       " 'adopter': 349,\n",
       " 'adoption': 350,\n",
       " 'adoptive': 351,\n",
       " 'adopts': 352,\n",
       " 'adorable': 353,\n",
       " 'adorableness': 354,\n",
       " 'adorably': 355,\n",
       " 'adoration': 356,\n",
       " 'adore': 357,\n",
       " 'adorn': 358,\n",
       " 'adornment': 359,\n",
       " 'adrenalin': 360,\n",
       " 'adrenaline': 361,\n",
       " 'adrian': 362,\n",
       " 'adriana': 363,\n",
       " 'adrianne': 364,\n",
       " 'adrien': 365,\n",
       " 'adrienne': 366,\n",
       " 'adrift': 367,\n",
       " 'adroit': 368,\n",
       " 'adroitly': 369,\n",
       " 'adulation': 370,\n",
       " 'adult': 371,\n",
       " 'adulterer': 372,\n",
       " 'adulterous': 373,\n",
       " 'adultery': 374,\n",
       " 'adulthood': 375,\n",
       " 'adultrous': 376,\n",
       " 'adults': 377,\n",
       " 'advance': 378,\n",
       " 'advanced': 379,\n",
       " 'advancement': 380,\n",
       " 'advantage': 381,\n",
       " 'advent': 382,\n",
       " 'adventure': 383,\n",
       " 'adventurer': 384,\n",
       " 'adventurous': 385,\n",
       " 'adversarial': 386,\n",
       " 'adversary': 387,\n",
       " 'adverse': 388,\n",
       " 'adversely': 389,\n",
       " 'adversity': 390,\n",
       " 'advertise': 391,\n",
       " 'advertised': 392,\n",
       " 'advertisement': 393,\n",
       " 'advertiser': 394,\n",
       " 'advertising': 395,\n",
       " 'advertisment': 396,\n",
       " 'advice': 397,\n",
       " 'advil': 398,\n",
       " 'advisable': 399,\n",
       " 'advise': 400,\n",
       " 'adviser': 401,\n",
       " 'advising': 402,\n",
       " 'advisor': 403,\n",
       " 'advocate': 404,\n",
       " 'advocatedirected': 405,\n",
       " 'advocating': 406,\n",
       " 'aerial': 407,\n",
       " 'aerosmith': 408,\n",
       " 'aerospace': 409,\n",
       " 'aesthetic': 410,\n",
       " 'aesthetically': 411,\n",
       " 'afar': 412,\n",
       " 'afeminite': 413,\n",
       " 'afer': 414,\n",
       " 'affability': 415,\n",
       " 'affable': 416,\n",
       " 'affair': 417,\n",
       " 'affay': 418,\n",
       " 'affect': 419,\n",
       " 'affectation': 420,\n",
       " 'affected': 421,\n",
       " 'affecting': 422,\n",
       " 'affection': 423,\n",
       " 'affectionate': 424,\n",
       " 'affectionately': 425,\n",
       " 'afficianados': 426,\n",
       " 'affiliate': 427,\n",
       " 'affiliated': 428,\n",
       " 'affiliation': 429,\n",
       " 'affinity': 430,\n",
       " 'affirm': 431,\n",
       " 'affirmation': 432,\n",
       " 'affirmative': 433,\n",
       " 'affleck': 434,\n",
       " 'afflict': 435,\n",
       " 'afflicted': 436,\n",
       " 'affliction': 437,\n",
       " 'affluent': 438,\n",
       " 'afford': 439,\n",
       " 'affordable': 440,\n",
       " 'affords': 441,\n",
       " 'affraid': 442,\n",
       " 'affront': 443,\n",
       " 'afi': 444,\n",
       " 'aficionado': 445,\n",
       " 'aficionados': 446,\n",
       " 'afield': 447,\n",
       " 'afire': 448,\n",
       " 'afloat': 449,\n",
       " 'afoot': 450,\n",
       " 'afore': 451,\n",
       " 'aforementioned': 452,\n",
       " 'aformentioned': 453,\n",
       " 'afoul': 454,\n",
       " 'afraid': 455,\n",
       " 'afred': 456,\n",
       " 'africa': 457,\n",
       " 'african': 458,\n",
       " 'africans': 459,\n",
       " 'afro': 460,\n",
       " 'aft': 461,\n",
       " 'after': 462,\n",
       " 'aftereffect': 463,\n",
       " 'afterglow': 464,\n",
       " 'afterlife': 465,\n",
       " 'aftermath': 466,\n",
       " 'afternoon': 467,\n",
       " 'afterschool': 468,\n",
       " 'aftertaste': 469,\n",
       " 'afterthought': 470,\n",
       " 'afterward': 471,\n",
       " 'afterwards': 472,\n",
       " 'afterword': 473,\n",
       " 'afun': 474,\n",
       " 'again': 475,\n",
       " 'against': 476,\n",
       " 'agamemnon': 477,\n",
       " 'agape': 478,\n",
       " 'agatha': 479,\n",
       " 'age': 480,\n",
       " 'aged': 481,\n",
       " 'agee': 482,\n",
       " 'agency': 483,\n",
       " 'agenda': 484,\n",
       " 'agent': 485,\n",
       " 'ages': 486,\n",
       " 'aggie': 487,\n",
       " 'aggravate': 488,\n",
       " 'aggravated': 489,\n",
       " 'aggravating': 490,\n",
       " 'aggravatingly': 491,\n",
       " 'aggravation': 492,\n",
       " 'aggression': 493,\n",
       " 'aggressive': 494,\n",
       " 'aggressivelly': 495,\n",
       " 'aggressively': 496,\n",
       " 'aggrieved': 497,\n",
       " 'aggrivate': 498,\n",
       " 'aghast': 499,\n",
       " 'agile': 500,\n",
       " 'agility': 501,\n",
       " 'aging': 502,\n",
       " 'agitate': 503,\n",
       " 'agitated': 504,\n",
       " 'agitation': 505,\n",
       " 'agnes': 506,\n",
       " 'agnieszka': 507,\n",
       " 'agnostic': 508,\n",
       " 'ago': 509,\n",
       " 'agonisingly': 510,\n",
       " 'agonize': 511,\n",
       " 'agonizing': 512,\n",
       " 'agonizingly': 513,\n",
       " 'agony': 514,\n",
       " 'agood': 515,\n",
       " 'agree': 516,\n",
       " 'agreeable': 517,\n",
       " 'agreeably': 518,\n",
       " 'agreement': 519,\n",
       " 'agrees': 520,\n",
       " 'agricultural': 521,\n",
       " 'aguilar': 522,\n",
       " 'aguirresarobe': 523,\n",
       " 'agutter': 524,\n",
       " 'ah': 525,\n",
       " 'ahab': 526,\n",
       " 'ahead': 527,\n",
       " 'aheart': 528,\n",
       " 'ahem': 529,\n",
       " 'ahern': 530,\n",
       " 'ahh': 531,\n",
       " 'ahmad': 532,\n",
       " 'ahmed': 533,\n",
       " 'ahmet': 534,\n",
       " 'ai': 535,\n",
       " 'aid': 536,\n",
       " 'aidan': 537,\n",
       " 'aide': 538,\n",
       " 'aided': 539,\n",
       " 'aiello': 540,\n",
       " 'ail': 541,\n",
       " 'ailing': 542,\n",
       " 'ailment': 543,\n",
       " 'aim': 544,\n",
       " 'aimee': 545,\n",
       " 'aimless': 546,\n",
       " 'aimlessly': 547,\n",
       " 'air': 548,\n",
       " 'airborne': 549,\n",
       " 'airbrush': 550,\n",
       " 'aircraft': 551,\n",
       " 'aire': 552,\n",
       " 'airhead': 553,\n",
       " 'airline': 554,\n",
       " 'airliner': 555,\n",
       " 'airlock': 556,\n",
       " 'airplane': 557,\n",
       " 'airplay': 558,\n",
       " 'airport': 559,\n",
       " 'airtime': 560,\n",
       " 'airwave': 561,\n",
       " 'airwaves': 562,\n",
       " 'airwolf': 563,\n",
       " 'airy': 564,\n",
       " 'aisle': 565,\n",
       " 'aisling': 566,\n",
       " 'aissa': 567,\n",
       " 'aix': 568,\n",
       " 'ajax': 569,\n",
       " 'ajay': 570,\n",
       " 'aka': 571,\n",
       " 'aki': 572,\n",
       " 'akiko': 573,\n",
       " 'akin': 574,\n",
       " 'akira': 575,\n",
       " 'akiva': 576,\n",
       " 'akroyd': 577,\n",
       " 'al': 578,\n",
       " 'ala': 579,\n",
       " 'alabama': 580,\n",
       " 'alacrity': 581,\n",
       " 'aladdin': 582,\n",
       " 'alain': 583,\n",
       " 'alakina': 584,\n",
       " 'alamo': 585,\n",
       " 'alan': 586,\n",
       " 'alana': 587,\n",
       " 'alanis': 588,\n",
       " 'alarm': 589,\n",
       " 'alarmed': 590,\n",
       " 'alas': 591,\n",
       " 'alaska': 592,\n",
       " 'alba': 593,\n",
       " 'albania': 594,\n",
       " 'albanian': 595,\n",
       " 'albany': 596,\n",
       " 'albarn': 597,\n",
       " 'albeit': 598,\n",
       " 'albert': 599,\n",
       " 'alberta': 600,\n",
       " 'albertin': 601,\n",
       " 'alberto': 602,\n",
       " 'albertson': 603,\n",
       " 'albino': 604,\n",
       " 'album': 605,\n",
       " 'alc': 606,\n",
       " 'alcatraz': 607,\n",
       " 'alchemy': 608,\n",
       " 'alcohol': 609,\n",
       " 'alcoholic': 610,\n",
       " 'alcoholism': 611,\n",
       " 'alcott': 612,\n",
       " 'alda': 613,\n",
       " 'alderaan': 614,\n",
       " 'aldous': 615,\n",
       " 'aldys': 616,\n",
       " 'alea': 617,\n",
       " 'alec': 618,\n",
       " 'alejandro': 619,\n",
       " 'alek': 620,\n",
       " 'alert': 621,\n",
       " 'alessa': 622,\n",
       " 'alessandro': 623,\n",
       " 'alevey': 624,\n",
       " 'alex': 625,\n",
       " 'alexa': 626,\n",
       " 'alexander': 627,\n",
       " 'alexandra': 628,\n",
       " 'alexandre': 629,\n",
       " 'alexandria': 630,\n",
       " 'alexis': 631,\n",
       " 'alf': 632,\n",
       " 'alferd': 633,\n",
       " 'alfie': 634,\n",
       " 'alfonso': 635,\n",
       " 'alfre': 636,\n",
       " 'alfred': 637,\n",
       " 'alfredo': 638,\n",
       " 'algae': 639,\n",
       " 'algar': 640,\n",
       " 'alger': 641,\n",
       " 'algeria': 642,\n",
       " 'ali': 643,\n",
       " 'alias': 644,\n",
       " 'alibi': 645,\n",
       " 'alice': 646,\n",
       " 'alicia': 647,\n",
       " 'alida': 648,\n",
       " 'alien': 649,\n",
       " 'alienate': 650,\n",
       " 'alienated': 651,\n",
       " 'alienation': 652,\n",
       " 'alienbusting': 653,\n",
       " 'aliens': 654,\n",
       " 'alight': 655,\n",
       " 'align': 656,\n",
       " 'alignment': 657,\n",
       " 'alike': 658,\n",
       " 'aline': 659,\n",
       " 'alison': 660,\n",
       " 'alive': 661,\n",
       " 'all': 662,\n",
       " 'allah': 663,\n",
       " 'allan': 664,\n",
       " 'allayah': 665,\n",
       " 'allegation': 666,\n",
       " 'allege': 667,\n",
       " 'alleged': 668,\n",
       " 'allegedly': 669,\n",
       " 'allegiance': 670,\n",
       " 'allegorical': 671,\n",
       " 'allegorically': 672,\n",
       " 'allegory': 673,\n",
       " 'allegra': 674,\n",
       " 'allen': 675,\n",
       " 'allergic': 676,\n",
       " 'allergy': 677,\n",
       " 'alleviate': 678,\n",
       " 'alley': 679,\n",
       " 'alleyway': 680,\n",
       " 'alli': 681,\n",
       " 'alliance': 682,\n",
       " 'allie': 683,\n",
       " 'allied': 684,\n",
       " 'alligator': 685,\n",
       " 'allison': 686,\n",
       " 'allman': 687,\n",
       " 'allocate': 688,\n",
       " 'allot': 689,\n",
       " 'allow': 690,\n",
       " 'allowance': 691,\n",
       " 'allows': 692,\n",
       " 'alloy': 693,\n",
       " 'allred': 694,\n",
       " 'allude': 695,\n",
       " 'allure': 696,\n",
       " 'alluring': 697,\n",
       " 'alluringly': 698,\n",
       " 'allusion': 699,\n",
       " 'allwhich': 700,\n",
       " 'ally': 701,\n",
       " 'allyson': 702,\n",
       " 'alma': 703,\n",
       " 'almanac': 704,\n",
       " 'almasy': 705,\n",
       " 'almod': 706,\n",
       " 'almost': 707,\n",
       " 'almosttoo': 708,\n",
       " 'aloft': 709,\n",
       " 'aloise': 710,\n",
       " 'alone': 711,\n",
       " 'along': 712,\n",
       " 'alongside': 713,\n",
       " 'aloof': 714,\n",
       " 'aloofness': 715,\n",
       " 'alot': 716,\n",
       " 'alotta': 717,\n",
       " 'aloud': 718,\n",
       " 'alp': 719,\n",
       " 'alpha': 720,\n",
       " 'alphonsia': 721,\n",
       " 'alpine': 722,\n",
       " 'alread': 723,\n",
       " 'already': 724,\n",
       " 'alright': 725,\n",
       " 'also': 726,\n",
       " 'altar': 727,\n",
       " 'alter': 728,\n",
       " 'alteration': 729,\n",
       " 'altercation': 730,\n",
       " 'altered': 731,\n",
       " 'alterior': 732,\n",
       " 'alternate': 733,\n",
       " 'alternately': 734,\n",
       " 'alternative': 735,\n",
       " 'alternatively': 736,\n",
       " 'alters': 737,\n",
       " 'althea': 738,\n",
       " 'although': 739,\n",
       " 'althoughi': 740,\n",
       " 'altitude': 741,\n",
       " 'altman': 742,\n",
       " 'altmanesque': 743,\n",
       " 'altmansome': 744,\n",
       " 'altogether': 745,\n",
       " 'altruist': 746,\n",
       " 'altruistic': 747,\n",
       " 'alum': 748,\n",
       " 'aluminium': 749,\n",
       " 'alumnus': 750,\n",
       " 'alums': 751,\n",
       " 'alvarado': 752,\n",
       " 'alvin': 753,\n",
       " 'alway': 754,\n",
       " 'always': 755,\n",
       " 'alyson': 756,\n",
       " 'alyssa': 757,\n",
       " 'alzheimer': 758,\n",
       " 'alzhiemer': 759,\n",
       " 'amadala': 760,\n",
       " 'amadeus': 761,\n",
       " 'amalgam': 762,\n",
       " 'amalgamation': 763,\n",
       " 'amanda': 764,\n",
       " 'amarcord': 765,\n",
       " 'amarillo': 766,\n",
       " 'amarky': 767,\n",
       " 'amass': 768,\n",
       " 'amateur': 769,\n",
       " 'amateurish': 770,\n",
       " 'amateurishly': 771,\n",
       " 'amateurism': 772,\n",
       " 'amaze': 773,\n",
       " 'amazed': 774,\n",
       " 'amazement': 775,\n",
       " 'amazes': 776,\n",
       " 'amazin': 777,\n",
       " 'amazing': 778,\n",
       " 'amazingly': 779,\n",
       " 'amazon': 780,\n",
       " 'amazona': 781,\n",
       " 'ambassador': 782,\n",
       " 'amber': 783,\n",
       " 'amberlike': 784,\n",
       " 'ambiance': 785,\n",
       " 'ambience': 786,\n",
       " 'ambient': 787,\n",
       " 'ambiguity': 788,\n",
       " 'ambiguous': 789,\n",
       " 'ambiguously': 790,\n",
       " 'ambiguousness': 791,\n",
       " 'ambition': 792,\n",
       " 'ambitionless': 793,\n",
       " 'ambitious': 794,\n",
       " 'ambitiously': 795,\n",
       " 'ambivalence': 796,\n",
       " 'ambivalent': 797,\n",
       " 'ambivlaent': 798,\n",
       " 'amble': 799,\n",
       " 'amblyn': 800,\n",
       " 'amboy': 801,\n",
       " 'amboys': 802,\n",
       " 'ambrose': 803,\n",
       " 'ambulance': 804,\n",
       " 'ambush': 805,\n",
       " 'amc': 806,\n",
       " 'amelie': 807,\n",
       " 'amen': 808,\n",
       " 'amend': 809,\n",
       " 'amendment': 810,\n",
       " 'amends': 811,\n",
       " 'amenity': 812,\n",
       " 'amercian': 813,\n",
       " 'america': 814,\n",
       " 'american': 815,\n",
       " 'americana': 816,\n",
       " 'americanise': 817,\n",
       " 'americanization': 818,\n",
       " 'americanize': 819,\n",
       " 'americanized': 820,\n",
       " 'americans': 821,\n",
       " 'amerman': 822,\n",
       " 'amerocentric': 823,\n",
       " 'ames': 824,\n",
       " 'amfibium': 825,\n",
       " 'ami': 826,\n",
       " 'amiable': 827,\n",
       " 'amicable': 828,\n",
       " 'amid': 829,\n",
       " 'amidala': 830,\n",
       " 'amidst': 831,\n",
       " 'amiel': 832,\n",
       " 'amigos': 833,\n",
       " 'amis': 834,\n",
       " 'amish': 835,\n",
       " 'amiss': 836,\n",
       " 'amistad': 837,\n",
       " 'amity': 838,\n",
       " 'ammo': 839,\n",
       " 'ammunition': 840,\n",
       " 'amnesia': 841,\n",
       " 'amnesiac': 842,\n",
       " 'amoeba': 843,\n",
       " 'amok': 844,\n",
       " 'amon': 845,\n",
       " 'among': 846,\n",
       " 'amongst': 847,\n",
       " 'amonkey': 848,\n",
       " 'amor': 849,\n",
       " 'amoral': 850,\n",
       " 'amorality': 851,\n",
       " 'amorous': 852,\n",
       " 'amos': 853,\n",
       " 'amount': 854,\n",
       " 'amourous': 855,\n",
       " 'ampbell': 856,\n",
       " 'amphetamine': 857,\n",
       " 'amphetimenes': 858,\n",
       " 'amphibian': 859,\n",
       " 'amphibious': 860,\n",
       " 'ample': 861,\n",
       " 'amplified': 862,\n",
       " 'amplify': 863,\n",
       " 'amply': 864,\n",
       " 'amputate': 865,\n",
       " 'amputation': 866,\n",
       " 'amrriage': 867,\n",
       " 'amsterdam': 868,\n",
       " 'amtrak': 869,\n",
       " 'amuck': 870,\n",
       " 'amulet': 871,\n",
       " 'amundsen': 872,\n",
       " 'amuse': 873,\n",
       " 'amused': 874,\n",
       " 'amusement': 875,\n",
       " 'amusing': 876,\n",
       " 'amusingly': 877,\n",
       " 'amy': 878,\n",
       " 'amyl': 879,\n",
       " 'amyls': 880,\n",
       " 'an': 881,\n",
       " 'ana': 882,\n",
       " 'anabasis': 883,\n",
       " 'anabelle': 884,\n",
       " 'anachronism': 885,\n",
       " 'anaconda': 886,\n",
       " 'anakin': 887,\n",
       " 'anakins': 888,\n",
       " 'anal': 889,\n",
       " 'analect': 890,\n",
       " 'analee': 891,\n",
       " 'anally': 892,\n",
       " 'analogous': 893,\n",
       " 'analogue': 894,\n",
       " 'analogy': 895,\n",
       " 'analyse': 896,\n",
       " 'analysis': 897,\n",
       " 'analyst': 898,\n",
       " 'analytic': 899,\n",
       " 'analytical': 900,\n",
       " 'analyzation': 901,\n",
       " 'analyze': 902,\n",
       " 'analyzed': 903,\n",
       " 'anamoly': 904,\n",
       " 'anand': 905,\n",
       " 'anarchic': 906,\n",
       " 'anarchist': 907,\n",
       " 'anarchy': 908,\n",
       " 'anastasia': 909,\n",
       " 'anatomical': 910,\n",
       " 'anatomically': 911,\n",
       " 'anatomize': 912,\n",
       " 'anatomy': 913,\n",
       " 'ancestor': 914,\n",
       " 'ancestral': 915,\n",
       " 'ancestry': 916,\n",
       " 'anchor': 917,\n",
       " 'anchorman': 918,\n",
       " 'ancient': 919,\n",
       " 'ancy': 920,\n",
       " 'and': 921,\n",
       " 'andaction': 922,\n",
       " 'andas': 923,\n",
       " 'anddiscovers': 924,\n",
       " 'anders': 925,\n",
       " 'andersen': 926,\n",
       " 'anderson': 927,\n",
       " 'andflawless': 928,\n",
       " 'andfor': 929,\n",
       " 'andguess': 930,\n",
       " 'andi': 931,\n",
       " 'andie': 932,\n",
       " 'andis': 933,\n",
       " 'andit': 934,\n",
       " 'andnever': 935,\n",
       " 'andre': 936,\n",
       " 'andrea': 937,\n",
       " 'andreas': 938,\n",
       " 'andree': 939,\n",
       " 'andrei': 940,\n",
       " 'andrew': 941,\n",
       " 'androginous': 942,\n",
       " 'androgony': 943,\n",
       " 'androgonys': 944,\n",
       " 'android': 945,\n",
       " 'androids': 946,\n",
       " 'andromeda': 947,\n",
       " 'andrus': 948,\n",
       " 'andrzej': 949,\n",
       " 'andsurprised': 950,\n",
       " 'andtells': 951,\n",
       " 'andthat': 952,\n",
       " 'andthe': 953,\n",
       " 'andthen': 954,\n",
       " 'andthere': 955,\n",
       " 'andthey': 956,\n",
       " 'andthis': 957,\n",
       " 'andthose': 958,\n",
       " 'andwe': 959,\n",
       " 'andwhen': 960,\n",
       " 'andwinks': 961,\n",
       " 'andy': 962,\n",
       " 'andygarcia': 963,\n",
       " 'anecdotal': 964,\n",
       " 'anecdote': 965,\n",
       " 'aneeka': 966,\n",
       " 'anemic': 967,\n",
       " 'anew': 968,\n",
       " 'ang': 969,\n",
       " 'angel': 970,\n",
       " 'angela': 971,\n",
       " 'angeles': 972,\n",
       " 'angelic': 973,\n",
       " 'angelica': 974,\n",
       " 'angelina': 975,\n",
       " 'angelo': 976,\n",
       " 'angelou': 977,\n",
       " 'angels': 978,\n",
       " 'anger': 979,\n",
       " 'angered': 980,\n",
       " 'angie': 981,\n",
       " 'anglade': 982,\n",
       " 'angle': 983,\n",
       " 'anglican': 984,\n",
       " 'anglo': 985,\n",
       " 'angrier': 986,\n",
       " 'angrily': 987,\n",
       " 'angry': 988,\n",
       " 'angst': 989,\n",
       " 'angstdom': 990,\n",
       " 'angsty': 991,\n",
       " 'anguish': 992,\n",
       " 'anguished': 993,\n",
       " 'angular': 994,\n",
       " 'angus': 995,\n",
       " 'anh': 996,\n",
       " 'anij': 997,\n",
       " 'animal': 998,\n",
       " 'animalistic': 999,\n",
       " 'animality': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dcd6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for i in reviews.iloc[:,1]:\n",
    "    xyz = i.split(' ')\n",
    "    row = []\n",
    "    for j in xyz:\n",
    "        row.append(dic[j])\n",
    "    new.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e07ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "this = []\n",
    "for i in range(2000):\n",
    "    this.append(i)\n",
    "score = np.array(score)\n",
    "d = {'Reviewings': new, 'Score': score}\n",
    "review_num = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93c6e3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewings</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9942, 277, 5148, 3019, 20919, 26774, 30552, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9148, 18175, 5130, 712, 27034, 26633, 9148, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[11084, 16627, 30916, 716, 11398, 7000, 19476,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14514, 22264, 9942, 11486, 1631, 24951, 25162...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[18181, 16294, 15972, 10982, 16714, 18717, 274...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[1120, 26383, 27288, 30290, 22731, 9942, 22724...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[14694, 3042, 31258, 11424, 4691, 6587, 10708,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[15097, 11978, 223, 27409, 27288, 15688, 24398...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[27986, 14694, 4041, 11595, 12888, 7326, 5887,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[28718, 20124, 11889, 2919, 12272, 11932, 6420...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviewings  Score\n",
       "0     [9942, 277, 5148, 3019, 20919, 26774, 30552, 2...      1\n",
       "1     [9148, 18175, 5130, 712, 27034, 26633, 9148, 1...      1\n",
       "2     [11084, 16627, 30916, 716, 11398, 7000, 19476,...      1\n",
       "3     [14514, 22264, 9942, 11486, 1631, 24951, 25162...      1\n",
       "4     [18181, 16294, 15972, 10982, 16714, 18717, 274...      1\n",
       "...                                                 ...    ...\n",
       "1995  [1120, 26383, 27288, 30290, 22731, 9942, 22724...      0\n",
       "1996  [14694, 3042, 31258, 11424, 4691, 6587, 10708,...      0\n",
       "1997  [15097, 11978, 223, 27409, 27288, 15688, 24398...      0\n",
       "1998  [27986, 14694, 4041, 11595, 12888, 7326, 5887,...      0\n",
       "1999  [28718, 20124, 11889, 2919, 12272, 11932, 6420...      0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24df9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(review_num.iloc[:,0],\n",
    "                                                      review_num.iloc[:,1],\n",
    "                                                      test_size = 0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee23be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "x_train = np.array(x_train)\n",
    "x_val = np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dc618a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9148, 31104, 12741, ...,     0,     0,     0],\n",
       "       [30931, 15488, 28147, ...,     0,     0,     0],\n",
       "       [ 3850, 12649,  2818, ..., 19361, 14859,  8711],\n",
       "       ...,\n",
       "       [30295,  2262,  7175, ...,     0,     0,     0],\n",
       "       [26387, 30361, 15262, ...,  1570, 27696, 18175],\n",
       "       [31024,  8247, 16294, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences(np.array(x_train), maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a389f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 1000\n",
    "x_train = pad_sequences(np.asarray(x_train), maxlen=max_length, padding='post')\n",
    "x_val = pad_sequences(np.asarray(x_val), maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b4df3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28343f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_3/embedding_5/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-46-662532357a46>\", line 18, in <module>\n      history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 197, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_3/embedding_5/embedding_lookup'\nindices[30,0] = 10354 is not in [0, 1600)\n\t [[{{node sequential_3/embedding_5/embedding_lookup}}]] [Op:__inference_train_function_2686]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-662532357a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m ])\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_3/embedding_5/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-46-662532357a46>\", line 18, in <module>\n      history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 197, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_3/embedding_5/embedding_lookup'\nindices[30,0] = 10354 is not in [0, 1600)\n\t [[{{node sequential_3/embedding_5/embedding_lookup}}]] [Op:__inference_train_function_2686]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding,GlobalMaxPooling1D, Conv1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "vocab_size = 1600\n",
    "max_length = 1000\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 8, input_length=max_length),\n",
    "   Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Flatten(),\n",
    "  Dense(1, activation='sigmoid'),\n",
    "  \n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "9fde8e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "2f842015",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "x_train = [torch.tensor(x) for x in x_train]\n",
    "X_train = nn.utils.rnn.pad_sequence(x_train, batch_first=True, padding_value=0).long()\n",
    "X_train = X_train.view(-1, batch_size, X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "04241a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_voc = int((X_train.max()+1).item())\n",
    "\n",
    "x_val = [torch.tensor(x) for x in x_val]\n",
    "X_val = nn.utils.rnn.pad_sequence(x_val, batch_first=True, padding_value=0).long()\n",
    "X_val = X_val.view(-1, batch_size, X_val.shape[1])\n",
    "\n",
    "y_train = torch.tensor(y_train).view(-1, batch_size)\n",
    "y_val = torch.tensor(y_val).view(-1, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64516564",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "24edac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "x_train = tf.convert_to_tensor(X_train, tf.float32)\n",
    "x_val = tf.convert_to_tensor(X_val, tf.float32)\n",
    "y_train = tf.cast(y_train, tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_val = tf.cast(y_val, tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "74ccecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 100, 1570).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_42\" (type Sequential).\n    \n    Input 0 of layer \"global_max_pooling1d_38\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 100, 1566, 128)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None, 100, 1570), dtype=float32)\n      â€¢ training=True\n      â€¢ mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-340-c2b533e14dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m ])\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Testing Accuracy is {} '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_42\" (type Sequential).\n    \n    Input 0 of layer \"global_max_pooling1d_38\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 100, 1566, 128)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None, 100, 1570), dtype=float32)\n      â€¢ training=True\n      â€¢ mask=None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding,GlobalMaxPooling1D, Conv1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(5000, 8, input_length=100),\n",
    "   Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))\n",
    "loss, accuracy = model.evaluate(x_val,y_val)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f5ec8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 100, 1570])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9fc8dfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 100)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "be1dec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 100, 1144])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e64dbf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "7b76a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,batch_size))\n",
    "y_val = np.asarray(y_val).astype('float32').reshape((-1,batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "85cd5933",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_41\" (type Sequential).\n\nInput 0 of layer \"conv1d_36\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (100, 1570)\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(100, 1570), dtype=float32)\n  â€¢ training=None\n  â€¢ mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-337-bd0200007a4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[0;32m    229\u001b[0m                          \u001b[1;34m'is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                          \u001b[1;34mf'expected min_ndim={spec.min_ndim}, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_41\" (type Sequential).\n\nInput 0 of layer \"conv1d_36\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (100, 1570)\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(100, 1570), dtype=float32)\n  â€¢ training=None\n  â€¢ mask=None"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "da2c1d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 100)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-341-d9c07de55e39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m---> 12\u001b[1;33m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m     13\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\gouth\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 100)).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "#model.add(Flatten())\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=100,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "bf911659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1570), dtype=float32, numpy=\n",
       "array([[29598.,  2818.,  5130., ...,     0.,     0.,     0.],\n",
       "       [ 4997.,  3428.,  1845., ...,     0.,     0.,     0.],\n",
       "       [22770.,   637., 12662., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [  814., 16322.,  5646., ...,     0.,     0.,     0.],\n",
       "       [27982., 23407., 16931., ...,     0.,     0.,     0.],\n",
       "       [ 3955., 15821.,  9197., ...,     0.,     0.,     0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "212ea4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create word embedding from scratch\n",
    "embeddings = nn.Embedding(len_voc, 100)\n",
    "\n",
    "# Build CNN model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embeddings = nn.Embedding(len_voc, 100)\n",
    "        self.cnn = nn.Conv2d(1, 100, (3, 100))\n",
    "        self.clf = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add word embeddings\n",
    "        x = self.embeddings(x)\n",
    "        # Add an extra dimension for CNN\n",
    "        x = x.unsqueeze(1)\n",
    "        # Apply CNN\n",
    "        x = self.cnn(x)\n",
    "        # Choose the maximum value of each filter and delete the extra dimension\n",
    "        x = x.max(2)[0].squeeze(2)\n",
    "        # Choose the most important features for the classification\n",
    "        x = F.relu(x) \n",
    "        #  Apply linear nn for classification\n",
    "        x = self.clf(x)\n",
    "        # Return the probability of positive and negative\n",
    "        return F.softmax(x, 1)\n",
    "\n",
    "# Use GPU for the model      \n",
    "model = Model()\n",
    "# opmization function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# calculate the loss\n",
    "criterio  = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ae4dc2a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-343-13febb79e399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-342-0ab8bc0c7a07>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Add word embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Add an extra dimension for CNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Function for evaluating\n",
    "def get_f1(X, y_real):\n",
    "  y_pred = []\n",
    "  for x in X:\n",
    "      # Choose the value with higher probability\n",
    "      y_pred.append(model(x.cuda()).argmax(1).cpu().detach())\n",
    "  y_pred = torch.cat(y_pred)\n",
    "  return metrics.f1_score(y_true=y_real, y_pred=y_pred)\n",
    "\n",
    "# Training steps\n",
    "epochs = 20\n",
    "LOSS = []\n",
    "for e in range(epochs):\n",
    "    for i, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "        \n",
    "        # Delete the prvious values of the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(tf.constant(x))\n",
    "        loss = criterio(y_pred, y)\n",
    "\n",
    "        # Compute the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply the optimization method for one step\n",
    "        optimizer.step()\n",
    "        \n",
    "        LOSS.append(loss.item())\n",
    "        if i%200==0:\n",
    "            with torch.no_grad():\n",
    "                f1 = get_f1(X_val, y_val)\n",
    "            print('Epoch: %d \\t Batch: %d \\t Loss: %.10f \\t F1_val: %.10f'%(e,i, torch.tensor(LOSS[-100:]).mean(), f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b108e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2bc90ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "op needs to be an Operation: tf.Tensor(\n[[ 9148. 31104. 12741. ...     0.     0.     0.]\n [30931. 15488. 28147. ...     0.     0.     0.]\n [30995.  6896.  9773. ...     0.     0.     0.]\n ...\n [ 8354. 24941. 15262. ...     0.     0.     0.]\n [12932. 25142. 23111. ...     0.     0.     0.]\n [14636. 12464. 20130. ...     0.     0.     0.]], shape=(100, 1570), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-344-6f024df39e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, op, value_index, dtype)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \"\"\"\n\u001b[0;32m    489\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"op needs to be an Operation: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: op needs to be an Operation: tf.Tensor(\n[[ 9148. 31104. 12741. ...     0.     0.     0.]\n [30931. 15488. 28147. ...     0.     0.     0.]\n [30995.  6896.  9773. ...     0.     0.     0.]\n ...\n [ 8354. 24941. 15262. ...     0.     0.     0.]\n [12932. 25142. 23111. ...     0.     0.     0.]\n [14636. 12464. 20130. ...     0.     0.     0.]], shape=(100, 1570), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training steps\n",
    "epochs = 20\n",
    "LOSS = []\n",
    "for e in range(epochs):\n",
    "    for i, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "        \n",
    "        # Delete the prvious values of the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(tf.Tensor(x, dtype='float32', value_index=batch_size))\n",
    "        loss = criterio(y_pred, y)\n",
    "\n",
    "        # Compute the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply the optimization method for one step\n",
    "        optimizer.step()\n",
    "        \n",
    "        LOSS.append(loss.item())\n",
    "        if i%200==0:\n",
    "            with torch.no_grad():\n",
    "                f1 = get_f1(X_val, y_val)\n",
    "            print('Epoch: %d \\t Batch: %d \\t Loss: %.10f \\t F1_val: %.10f'%(e,i, torch.tensor(LOSS[-100:]).mean(), f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6bdcd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Function for evaluating\n",
    "def get_f1(X, y_real):\n",
    "  y_pred = []\n",
    "  for x in X:\n",
    "      # Choose the value with higher probability\n",
    "      y_pred.append(model(x).argmax(1).cpu().detach())\n",
    "  y_pred = torch.cat(y_pred)\n",
    "  return metrics.f1_score(y_true=y_real, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-346-f8a9d57cebb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-342-0ab8bc0c7a07>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Add word embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Add an extra dimension for CNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training steps\n",
    "epochs = 1000\n",
    "LOSS = []\n",
    "for e in range(epochs):\n",
    "    for i, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "        \n",
    "        # Delete the prvious values of the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = criterio(y_pred, y)\n",
    "\n",
    "        # Compute the gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply the optimization method for one step\n",
    "        optimizer.step()\n",
    "        \n",
    "        LOSS.append(loss.item())\n",
    "        if i%200==0:\n",
    "            with torch.no_grad():\n",
    "                f1 = get_f1(x_val, y_val)\n",
    "            print('Epoch: %d \\t Batch: %d \\t Loss: %.10f \\t F1_val: %.10f'%(e,i, torch.tensor(LOSS[-100:]).mean(), f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "795224b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-347-7353aae27b00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-342-0ab8bc0c7a07>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Add word embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Add an extra dimension for CNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tensorflow.python.framework.ops.EagerTensor"
     ]
    }
   ],
   "source": [
    "model(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2925c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
